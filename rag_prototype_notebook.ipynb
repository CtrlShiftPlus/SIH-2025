{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# RAG Prototype Notebook\n",
    "\n",
    "This notebook walks through creating a retrieval-augmented generation (RAG) prototype using your `all_district_data.json` file.\n",
    "\n",
    "**What it does:**\n",
    "- Inspect the collected JSON data\n",
    "- Convert records into text documents (with metadata)\n",
    "- Save documents and a `train.jsonl` of generated QA pairs\n",
    "- (Optional) Build embeddings using `sentence-transformers` and a FAISS index\n",
    "- Run a simple retrieval test\n",
    "\n",
    "**How to run:**\n",
    "- If you haven't produced `all_district_data.json` yet, run your collector script first (e.g. `python dbcollection_final.py`).\n",
    "- Install required packages when prompted in the cells (e.g. `pip install sentence-transformers faiss-cpu`)\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook generated automatically by ChatGPT â€” edit cells as needed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "inspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 743 records\n",
      "\n",
      "Top-level keys in first record:\n",
      "['locationName', 'area', 'loss', 'category', 'reportSummary', 'gwProjectedUtilAllocationDynamicAquifer', 'additionalRecharge', 'staticGWResource', 'totalGWAvailability', 'aquiferBusinessData', 'coastalBusinessData', 'waterDepletedZonesBusinessData', 'inOutFlow', 'baseFlow', 'streamRecharge', 'additionalbaseflow', 'envFlows', 'subject', 'action', 'modifiable', 'isUrban', 'gwSpecificYield', 'geology', 'evaporation', 'qualityTagging', 'approvalLevel', 'verificStatus', 'timeStamp', 'locationUUID', 'rainfall', 'wtfonly', 'computationSummary', 'rechargeData', 'draftData', 'currentAvailabilityForAllPurposes', 'availabilityForFutureUse', 'gwallocation', 'stageOfExtraction', 'gwlevelData', 'gwanalysisSeason', 'gwtrendSlope', 'waterTableRiseFall', 'gwtrendAttention', 'waterTableCategory', 'message']\n",
      "\n",
      "Example record (pretty):\n",
      "{ \"locationName\": \"SHEOPUR\", \"area\": { \"non_recharge_worthy\": { \"commandArea\": 0.0, \"nonCommandArea\": 0.0, \"poorQualityArea\": 0.0, \"hillyArea\": 0.0, \"forestArea\": 0.0, \"totalArea\": 127120.0, \"pavedArea\": 0.0, \"unpavedArea\": 0.0 }, \"total\": { \"commandArea\": 71150.0, \"nonCommandArea\": 462330.0, \"poorQualityArea\": 0.0, \"hillyArea\": 0.0, \"forestArea\": 0.0, \"totalArea\": 660600.0, \"pavedArea\": 0.0, \"unpavedArea\": 0.0 }, \"recharge_worthy\": { \"commandArea\": 71150.0, \"nonCommandArea\": 462330.0, \"poorQualityArea\": 0.0, \"hillyArea\": 0.0, \"forestArea\": 0.0, \"totalArea\": 533480.0, \"pavedArea\": 0.0, \"unpavedArea\": 0.0 } }, \"loss\": { \"poor_quality\": 0.0, \"total\": 4406.91, \"non_command\": 2010.3899999999999, \"command\": 2396.5199999999995 }, \"category\": { \"total\": \"safe\", \"non_command\": \"safe\", \"command\": \"safe\" }, \"reportSummary\": { \"ac6c2a8c-f447-4281-9fe7-3182a9a46bc0\": { \"BLOCK\": { \"semi_critical\": 1 } }, \"total\": { \"BLOCK\": { \"semi_critical\": 1, \"safe\": 2 } }, \"63a00de0-b30c-4e2a-a83e-cc1a32f30f22\": { \"BLOCK\": { \"safe\": 1 } }, \"a5cd3db4-706e-4f27-8b39-30ebe0d02b98\": { \"BLOCK\": { \"safe\": 1 } } }, \"gwProjectedUtilAllocationDynamicAquifer\": { \"domestic\": { \"total\": 0.0 }, \"total\": { \"total\": 0.0 } }, \"additionalRecharge\": {}, \"staticGWResource\": { \"poor_quality\": 0.0, \"total\": 0.0, \"non_command\": 0.0, \"command\": 0.0 }, \"totalGWAvailability\": { \"poor_quality\": 0.0, \"total\": 51584.3, \"non_command\": 29296.03, \"command\": 22288.269999999997 }, \"aquiferBusinessData\": { \"confined_aquifer\": { \"total\": { \"total\": 0.0 }, \"in_storage_gw\": { \"in_storage_gw\": 0.0 }, \"dynamic_gw\": { \"dynamic_gw\": 0.0 } } }, \"coastalBusinessData\": null, \"waterDepletedZonesBusinessData\": null, \"inOutFlow\": { \"total\": 0.0 }, \"baseFlow\": { \"total\": { \"lateral_aquifer\": 0.0, \"vertcal_aquifer\": 0.0 } }, \"streamRecharge\": null, \"additionalbaseflow\": null, \"envFlows\": null, \"subject\": null, \"action\": null, \"modifiable\": null, \"isUrban\": null, \"gwSpecificYield\": null, \"geology\": null, \"evaporation\": {}, [...]\n",
      "Saved sample to sample_records.json\n"
     ]
    }
   ],
   "source": [
    "# 1) Inspect dataset\n",
    "import os, json\n",
    "fn = 'all_district_data.json'\n",
    "if not os.path.exists(fn):\n",
    "    print(f\"File not found: {fn}. Make sure to run your collector script (e.g. python dbcollection_final.py) to produce it.\")\n",
    "else:\n",
    "    with open(fn,'r',encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    print('Loaded', len(data), 'records')\n",
    "    if len(data) > 0:\n",
    "        print('\\nTop-level keys in first record:')\n",
    "        print(list(data[0].keys()))\n",
    "        import textwrap\n",
    "        print('\\nExample record (pretty):')\n",
    "        print(textwrap.shorten(json.dumps(data[0], ensure_ascii=False, indent=2), width=2000))\n",
    "\n",
    "# Save small sample for quick inspection\n",
    "with open('sample_records.json','w',encoding='utf-8') as f:\n",
    "    json.dump(data[:10], f, ensure_ascii=False, indent=2)\n",
    "print('Saved sample to sample_records.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "docs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 743 documents to docs.json and docs.jsonl\n",
      "Saved 743 QA pairs to train.jsonl\n"
     ]
    }
   ],
   "source": [
    "import re, json\n",
    "\n",
    "def record_to_text(rec, keys_order=None):\n",
    "    lines = []\n",
    "    if keys_order is None:\n",
    "        keys = list(rec.keys())\n",
    "    else:\n",
    "        keys = [k for k in keys_order if k in rec] + [k for k in rec if k not in (keys_order or [])]\n",
    "    for k in keys:\n",
    "        v = rec.get(k)\n",
    "        if v is None:\n",
    "            continue\n",
    "        if isinstance(v, (list, tuple)):\n",
    "            try:\n",
    "                val = ', '.join(map(str, v))\n",
    "            except Exception:\n",
    "                val = str(v)\n",
    "        elif isinstance(v, dict):\n",
    "            val = json.dumps(v, ensure_ascii=False)\n",
    "        else:\n",
    "            val = str(v)\n",
    "        val = re.sub(r'\\s+', ' ', val).strip()\n",
    "        lines.append(f\"{k}: {val}\")\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "fn = 'all_district_data.json'\n",
    "with open(fn,'r',encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "docs = []\n",
    "for i, rec in enumerate(data):\n",
    "    text = record_to_text(rec)\n",
    "    meta = { 'source_id': i }\n",
    "    for possible_name_key in ['locationName', 'area', 'loss', 'category', 'reportSummary', 'gwProjectedUtilAllocationDynamicAquifer', 'additionalRecharge', 'staticGWResource', 'totalGWAvailability', 'aquiferBusinessData', 'coastalBusinessData', 'waterDepletedZonesBusinessData', 'inOutFlow', 'baseFlow', 'streamRecharge', 'additionalbaseflow', 'envFlows', 'subject', 'action', 'modifiable', 'isUrban', 'gwSpecificYield', 'geology', 'evaporation', 'qualityTagging', 'approvalLevel', 'verificStatus', 'timeStamp', 'locationUUID', 'rainfall', 'wtfonly', 'computationSummary', 'rechargeData', 'draftData', 'currentAvailabilityForAllPurposes', 'availabilityForFutureUse', 'gwallocation', 'stageOfExtraction', 'gwlevelData', 'gwanalysisSeason', 'gwtrendSlope', 'waterTableRiseFall', 'gwtrendAttention', 'waterTableCategory', 'message']:\n",
    "        if possible_name_key in rec:\n",
    "            meta['title'] = rec.get(possible_name_key)\n",
    "            break\n",
    "    docs.append({'id': str(i), 'text': text, 'meta': meta})\n",
    "\n",
    "with open('docs.json','w',encoding='utf-8') as f:\n",
    "    json.dump(docs, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open('docs.jsonl','w',encoding='utf-8') as f:\n",
    "    for d in docs:\n",
    "        f.write(json.dumps(d, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print('Saved', len(docs), 'documents to docs.json and docs.jsonl')\n",
    "\n",
    "# Generate QA pairs\n",
    "train_pairs = []\n",
    "for d in docs:\n",
    "    title = d['meta'].get('title', f\"record {d['id']}\")\n",
    "    q = f\"What information do you have about {title}?\"\n",
    "    a = d['text']\n",
    "    train_pairs.append({'instruction': q, 'output': a})\n",
    "\n",
    "with open('train.jsonl','w',encoding='utf-8') as f:\n",
    "    for p in train_pairs:\n",
    "        f.write(json.dumps(p, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print('Saved', len(train_pairs), 'QA pairs to train.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "embeddings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FAISS index and metadata\n"
     ]
    }
   ],
   "source": [
    "# 3) OPTIONAL: Build embeddings + FAISS index\n",
    "# Install first: pip install -U sentence-transformers faiss-cpu\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np, faiss, json\n",
    "\n",
    "with open('docs.json','r',encoding='utf-8') as f:\n",
    "    docs = json.load(f)\n",
    "\n",
    "texts = [d['text'] for d in docs]\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "embs = model.encode(texts, show_progress_bar=False, convert_to_numpy=True)\n",
    "faiss.normalize_L2(embs)\n",
    "d = embs.shape[1]\n",
    "index = faiss.IndexFlatIP(d)\n",
    "index.add(embs)\n",
    "\n",
    "faiss.write_index(index, 'districts.index')\n",
    "with open('docs_meta.json','w',encoding='utf-8') as f:\n",
    "    json.dump([d['meta'] for d in docs], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print('Saved FAISS index and metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "retrieval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What is the total command area of SHEOPUR?\n",
      " Rank 1: doc_id=376, title=HISAR\n",
      "  snippet: locationName: HISAR area: {\"non_recharge_worthy\": {\"commandArea\": 0.0, \"nonCommandArea\": 0.0, \"poorQualityArea\": 0.0, \"hillyArea\": 0.0, \"forestArea\": 0.0, \"totalArea\": 0.0, \"pavedArea\": 0.0, \"unpavedArea\": 0.0}, \"total\": {\"commandArea\": 406838.29692163103, \"nonCommandArea\": 0.0, \"poorQualityArea\": 6...\n",
      " Rank 2: doc_id=176, title=Faridkot\n",
      "  snippet: locationName: Faridkot area: {\"non_recharge_worthy\": {\"commandArea\": 0.0, \"nonCommandArea\": 0.0, \"poorQualityArea\": 0.0, \"hillyArea\": 0.0, \"forestArea\": 0.0, \"totalArea\": 0.0, \"pavedArea\": 0.0, \"unpavedArea\": 0.0}, \"total\": {\"commandArea\": 92275.49, \"nonCommandArea\": 0.0, \"poorQualityArea\": 55322.50...\n",
      " Rank 3: doc_id=128, title=SHEOHAR\n",
      "  snippet: locationName: SHEOHAR area: {\"non_recharge_worthy\": {\"commandArea\": 0.0, \"nonCommandArea\": 0.0, \"poorQualityArea\": 0.0, \"hillyArea\": 0.0, \"forestArea\": 0.0, \"totalArea\": 0.0, \"pavedArea\": 0.0, \"unpavedArea\": 0.0}, \"total\": {\"commandArea\": 12235.0, \"nonCommandArea\": 32064.0, \"poorQualityArea\": 0.0, \"...\n",
      " Rank 4: doc_id=721, title=DEVBHUMI DWARKA\n",
      "  snippet: locationName: DEVBHUMI DWARKA area: {\"non_recharge_worthy\": {\"commandArea\": 0.0, \"nonCommandArea\": 0.0, \"poorQualityArea\": 0.0, \"hillyArea\": 0.0, \"forestArea\": 0.0, \"totalArea\": 12245.0, \"pavedArea\": 0.0, \"unpavedArea\": 0.0}, \"total\": {\"commandArea\": 360785.62323287915, \"nonCommandArea\": 0.0, \"poorQ...\n",
      " Rank 5: doc_id=650, title=COIMBATORE\n",
      "  snippet: locationName: COIMBATORE area: {\"non_recharge_worthy\": {\"commandArea\": 0.0, \"nonCommandArea\": 0.0, \"poorQualityArea\": 0.0, \"hillyArea\": 0.0, \"forestArea\": 0.0, \"totalArea\": 6647.13, \"pavedArea\": 0.0, \"unpavedArea\": 0.0}, \"total\": {\"commandArea\": 29882.630999999998, \"nonCommandArea\": 330568.179000000...\n",
      "\n",
      "Query: Which category is assigned to Sheopur?\n",
      " Rank 1: doc_id=405, title=Ahmednagar\n",
      "  snippet: locationName: Ahmednagar area: {} category: {} approvalLevel: 4 verificStatus: 1 locationUUID: 39479641-fa67-4329-b39d-4d011c142305 stageOfExtraction: {}...\n",
      " Rank 2: doc_id=711, title=RANA AND KUTCH\n",
      "  snippet: locationName: RANA AND KUTCH area: {\"non_recharge_worthy\": {\"commandArea\": 0.0, \"nonCommandArea\": 0.0, \"poorQualityArea\": 0.0, \"hillyArea\": 0.0, \"forestArea\": 0.0, \"totalArea\": 0.0, \"pavedArea\": 0.0, \"unpavedArea\": 0.0}, \"total\": {\"commandArea\": 0.0, \"nonCommandArea\": 0.0, \"poorQualityArea\": 0.0, \"h...\n",
      " Rank 3: doc_id=128, title=SHEOHAR\n",
      "  snippet: locationName: SHEOHAR area: {\"non_recharge_worthy\": {\"commandArea\": 0.0, \"nonCommandArea\": 0.0, \"poorQualityArea\": 0.0, \"hillyArea\": 0.0, \"forestArea\": 0.0, \"totalArea\": 0.0, \"pavedArea\": 0.0, \"unpavedArea\": 0.0}, \"total\": {\"commandArea\": 12235.0, \"nonCommandArea\": 32064.0, \"poorQualityArea\": 0.0, \"...\n",
      " Rank 4: doc_id=506, title=Dakshina Kannada\n",
      "  snippet: locationName: Dakshina Kannada area: {\"non_recharge_worthy\": {\"commandArea\": 0.0, \"nonCommandArea\": 0.0, \"poorQualityArea\": 0.0, \"hillyArea\": 0.0, \"forestArea\": 0.0, \"totalArea\": 128476.0, \"pavedArea\": 0.0, \"unpavedArea\": 0.0}, \"total\": {\"commandArea\": 0.0, \"nonCommandArea\": 357624.0, \"poorQualityAr...\n",
      " Rank 5: doc_id=376, title=HISAR\n",
      "  snippet: locationName: HISAR area: {\"non_recharge_worthy\": {\"commandArea\": 0.0, \"nonCommandArea\": 0.0, \"poorQualityArea\": 0.0, \"hillyArea\": 0.0, \"forestArea\": 0.0, \"totalArea\": 0.0, \"pavedArea\": 0.0, \"unpavedArea\": 0.0}, \"total\": {\"commandArea\": 406838.29692163103, \"nonCommandArea\": 0.0, \"poorQualityArea\": 6...\n"
     ]
    }
   ],
   "source": [
    "# 4) Retrieval test\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss, json, numpy as np\n",
    "\n",
    "index = faiss.read_index('districts.index')\n",
    "with open('docs.json','r',encoding='utf-8') as f:\n",
    "    docs = json.load(f)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "queries = [\n",
    "    \"What is the total command area of SHEOPUR?\",\n",
    "    \"Which category is assigned to Sheopur?\",\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    q_emb = model.encode([q], convert_to_numpy=True)\n",
    "    faiss.normalize_L2(q_emb)\n",
    "    D, I = index.search(q_emb, k=5)\n",
    "    print('\\nQuery:', q)\n",
    "    for rank, idx in enumerate(I[0]):\n",
    "        doc = docs[idx]\n",
    "        print(f' Rank {rank+1}: doc_id={doc[\"id\"]}, title={doc[\"meta\"].get(\"title\")}')\n",
    "        print('  snippet:', doc['text'][:300].replace('\\n',' ') + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt",
   "metadata": {},
   "source": [
    "## 5) Example RAG Prompt Template\n",
    "```\n",
    "You are a helpful assistant. Use the following sources to answer the question. If not found, say \"I don't know\".\n",
    "\n",
    "SOURCES:\n",
    "[1] <passage 1>\n",
    "[2] <passage 2>\n",
    "\n",
    "QUESTION: <user question>\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
